<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>John  Mitros | publications</title>
    <meta name="author" content="John  Mitros" />
    <meta name="description" content="in reversed chronological order." />
    <meta name="keywords" content="machine learning, statistics, optimisation, robustness, bayesian, academic-website, john mitros, google scholar" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/cap5.png"/>
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://jmitros.github.io/publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://jmitros.github.io/"><span class="font-weight-bold">John</span>   Mitros</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/assets/pdf/cv.pdf">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">in reversed chronological order.</p>
          </header>

          <article>
            <p>An up-to-date list is available on <a href="https://scholar.google.com/citations?user=FQraBxgAAAAJ" target="_blank" rel="noopener noreferrer">Google Scholar</a>.</p>

<h2 id="refereed-articles">refereed articles</h2>

<!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2021</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICONIP</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2021&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2021,\n  talk = {https://www.google.com},\n  author = {Mitros, John and Mac Namee, Brian},\n  title = {On the Importance of Regularisation and Auxiliary\n                    Information in OOD Detection},\n  booktitle = {International Conference of Neural Information\n                    Processing, (ICONIP),},\n  year = {2021},\n  isbn = {978-3-030-92310-5},\n  doi = {10.1007/978-3-030-92310-5_42},\n  abbr = {ICONIP},\n  arxiv = {2107.07564}\n}\n&quot;,&quot;talk&quot;:&quot;https://www.google.com&quot;,&quot;author&quot;:&quot;Mitros, John and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;Mac Namee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;On the Importance of Regularisation and Auxiliary\n                  Information in OOD Detection&quot;,&quot;booktitle&quot;:&quot;International Conference of Neural Information\n                  Processing, (ICONIP),&quot;,&quot;year&quot;:&quot;2021&quot;,&quot;isbn&quot;:&quot;978-3-030-92310-5&quot;,&quot;doi&quot;:&quot;10.1007/978-3-030-92310-5_42&quot;,&quot;abstract&quot;:&quot;Neural networks are often utilised in critical\n                  domain applications (e.g. self-driving cars,\n                  financial markets, and aerospace engineering), even\n                  though they exhibit overconfident predictions for\n                  ambiguous inputs. This deficiency demonstrates a\n                  fundamental flaw indicating that neural networks\n                  often overfit on spurious correlations. To address\n                  this problem in this work we present two novel\n                  objectives that improve the ability of a network to\n                  detect out-of-distribution samples and therefore\n                  avoid overconfident predictions for ambiguous\n                  inputs. We empirically demonstrate that our methods\n                  outperform the baseline and perform better than the\n                  majority of existing approaches, while performing\n                  competitively those that they don’t\n                  outperform. Additionally, we empirically demonstrate\n                  the robustness of our approach against common\n                  corruptions and demonstrate the importance of\n                  regularisation and auxiliary information in\n                  out-of-distribution detection.&quot;,&quot;abbr&quot;:&quot;ICONIP&quot;,&quot;arxiv&quot;:&quot;2107.07564&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2021\&quot;&gt;Mitros, J., &amp;amp; Mac Namee, B. (2021). On the Importance of Regularisation and Auxiliary\n                  Information in OOD Detection. &lt;i&gt;International Conference of Neural Information\n                  Processing, (ICONIP),&lt;/i&gt; https://doi.org/10.1007/978-3-030-92310-5_42&lt;/span&gt;&quot; -->
        <div id="mitros2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On the Importance of Regularisation and Auxiliary
                  Information in OOD Detection</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, and <a href="https://people.ucd.ie/brian.macnamee" target="_blank" rel="noopener noreferrer">Mac Namee, Brian</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2021&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2021,\n  talk = {https://www.google.com},\n  author = {Mitros, John and Mac Namee, Brian},\n  title = {On the Importance of Regularisation and Auxiliary\n                    Information in OOD Detection},\n  booktitle = {International Conference of Neural Information\n                    Processing, (ICONIP),},\n  year = {2021},\n  isbn = {978-3-030-92310-5},\n  doi = {10.1007/978-3-030-92310-5_42},\n  abbr = {ICONIP},\n  arxiv = {2107.07564}\n}\n&quot;,&quot;talk&quot;:&quot;https://www.google.com&quot;,&quot;author&quot;:&quot;Mitros, John and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;Mac Namee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;On the Importance of Regularisation and Auxiliary\n                  Information in OOD Detection&quot;,&quot;booktitle&quot;:&quot;International Conference of Neural Information\n                  Processing, (ICONIP),&quot;,&quot;year&quot;:&quot;2021&quot;,&quot;isbn&quot;:&quot;978-3-030-92310-5&quot;,&quot;doi&quot;:&quot;10.1007/978-3-030-92310-5_42&quot;,&quot;abstract&quot;:&quot;Neural networks are often utilised in critical\n                  domain applications (e.g. self-driving cars,\n                  financial markets, and aerospace engineering), even\n                  though they exhibit overconfident predictions for\n                  ambiguous inputs. This deficiency demonstrates a\n                  fundamental flaw indicating that neural networks\n                  often overfit on spurious correlations. To address\n                  this problem in this work we present two novel\n                  objectives that improve the ability of a network to\n                  detect out-of-distribution samples and therefore\n                  avoid overconfident predictions for ambiguous\n                  inputs. We empirically demonstrate that our methods\n                  outperform the baseline and perform better than the\n                  majority of existing approaches, while performing\n                  competitively those that they don’t\n                  outperform. Additionally, we empirically demonstrate\n                  the robustness of our approach against common\n                  corruptions and demonstrate the importance of\n                  regularisation and auxiliary information in\n                  out-of-distribution detection.&quot;,&quot;abbr&quot;:&quot;ICONIP&quot;,&quot;arxiv&quot;:&quot;2107.07564&quot;} -->
          <div class="periodical">
            <em>In International Conference of Neural Information
                  Processing, (ICONIP),</em> 2021
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2107.07564" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="https://www.google.com" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Talk</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Neural networks are often utilised in critical
                  domain applications (e.g. self-driving cars,
                  financial markets, and aerospace engineering), even
                  though they exhibit overconfident predictions for
                  ambiguous inputs. This deficiency demonstrates a
                  fundamental flaw indicating that neural networks
                  often overfit on spurious correlations. To address
                  this problem in this work we present two novel
                  objectives that improve the ability of a network to
                  detect out-of-distribution samples and therefore
                  avoid overconfident predictions for ambiguous
                  inputs. We empirically demonstrate that our methods
                  outperform the baseline and perform better than the
                  majority of existing approaches, while performing
                  competitively those that they don’t
                  outperform. Additionally, we empirically demonstrate
                  the robustness of our approach against common
                  corruptions and demonstrate the importance of
                  regularisation and auxiliary information in
                  out-of-distribution detection.</p>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECCV</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2020&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2020,\n  author = {Mitros, John and Pakrashi, Arjun and Mac Namee, Brian},\n  title = {Ramifications of Approximate Posterior Inference for\n                    Bayesian Deep Learning in Adversarial and\n                    Out-of-Distribution Settings},\n  booktitle = {Proceedings of Computer Vision - (ECCV) Workshops,},\n  series = {Lecture Notes in Computer Science},\n  volume = {12535},\n  pages = {71--87},\n  publisher = {Springer},\n  year = {2020},\n  doi = {10.1007/978-3-030-66415-2_5},\n  abbr = {ECCV},\n  arxiv = {2009.01798}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Pakrashi, Arjun and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Arjun&quot;,&quot;last&quot;:&quot;Pakrashi&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Arjun&quot;,&quot;author_1_last&quot;:&quot;Pakrashi&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Brian&quot;,&quot;author_2_last&quot;:&quot;Mac Namee&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Ramifications of Approximate Posterior Inference for\n                  Bayesian Deep Learning in Adversarial and\n                  Out-of-Distribution Settings&quot;,&quot;booktitle&quot;:&quot;Proceedings of Computer Vision - (ECCV) Workshops,&quot;,&quot;series&quot;:&quot;Lecture Notes in Computer Science&quot;,&quot;volume&quot;:&quot;12535&quot;,&quot;pages&quot;:&quot;71–87&quot;,&quot;publisher&quot;:&quot;Springer&quot;,&quot;year&quot;:&quot;2020&quot;,&quot;doi&quot;:&quot;10.1007/978-3-030-66415-2_5&quot;,&quot;abbr&quot;:&quot;ECCV&quot;,&quot;abstract&quot;:&quot;Deep neural networks have been successful in diverse\n                  discriminative classification tasks, although, they\n                  are poorly calibrated often assigning high\n                  probability to misclassified predictions. Potential\n                  consequences could lead to trustworthiness and\n                  accountability of the models when deployed in real\n                  applications, where predictions are evaluated based\n                  on their confidence scores. Existing solutions\n                  suggest the benefits attained by combining deep\n                  neural networks and Bayesian inference to quantify\n                  uncertainty over the models’ predictions for\n                  ambiguous datapoints. In this work we propose to\n                  validate and test the efficacy of likelihood based\n                  models in the task of out of distribution detection\n                  (OoD). Across different datasets and metrics we show\n                  that Bayesian deep learning models on certain\n                  occasions marginally outperform conventional neural\n                  networks and in the event of minimal overlap between\n                  in/out distribution classes, even the best models\n                  exhibit a reduction in AUC scores in detecting OoD\n                  data. Preliminary investigations indicate the\n                  potential inherent role of bias due to choices of\n                  initialisation, architecture or activation\n                  functions. We hypothesise that the sensitivity of\n                  neural networks to unseen inputs could be a\n                  multi-factor phenomenon arising from the different\n                  architectural design choices often amplified by the\n                  curse of dimensionality. Furthermore, we perform a\n                  study to find the effect of the adversarial noise\n                  resistance methods on in and out-of-distribution\n                  performance, as well as, also investigate\n                  adversarial noise robustness of Bayesian deep\n                  learners.&quot;,&quot;arxiv&quot;:&quot;2009.01798&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2020\&quot;&gt;Mitros, J., Pakrashi, A., &amp;amp; Mac Namee, B. (2020). Ramifications of Approximate Posterior Inference for\n                  Bayesian Deep Learning in Adversarial and\n                  Out-of-Distribution Settings. &lt;i&gt;Proceedings of Computer Vision - (ECCV) Workshops,&lt;/i&gt; &lt;i&gt;12535&lt;/i&gt;, 71–87. https://doi.org/10.1007/978-3-030-66415-2_5&lt;/span&gt;&quot; -->
        <div id="mitros2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Ramifications of Approximate Posterior Inference for
                  Bayesian Deep Learning in Adversarial and
                  Out-of-Distribution Settings</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, <a href="https://scholar.google.com/citations?user=G0FkHtYAAAAJ" target="_blank" rel="noopener noreferrer">Pakrashi, Arjun</a>, and <a href="https://people.ucd.ie/brian.macnamee" target="_blank" rel="noopener noreferrer">Mac Namee, Brian</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2020&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2020,\n  author = {Mitros, John and Pakrashi, Arjun and Mac Namee, Brian},\n  title = {Ramifications of Approximate Posterior Inference for\n                    Bayesian Deep Learning in Adversarial and\n                    Out-of-Distribution Settings},\n  booktitle = {Proceedings of Computer Vision - (ECCV) Workshops,},\n  series = {Lecture Notes in Computer Science},\n  volume = {12535},\n  pages = {71--87},\n  publisher = {Springer},\n  year = {2020},\n  doi = {10.1007/978-3-030-66415-2_5},\n  abbr = {ECCV},\n  arxiv = {2009.01798}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Pakrashi, Arjun and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Arjun&quot;,&quot;last&quot;:&quot;Pakrashi&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Arjun&quot;,&quot;author_1_last&quot;:&quot;Pakrashi&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Brian&quot;,&quot;author_2_last&quot;:&quot;Mac Namee&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Ramifications of Approximate Posterior Inference for\n                  Bayesian Deep Learning in Adversarial and\n                  Out-of-Distribution Settings&quot;,&quot;booktitle&quot;:&quot;Proceedings of Computer Vision - (ECCV) Workshops,&quot;,&quot;series&quot;:&quot;Lecture Notes in Computer Science&quot;,&quot;volume&quot;:&quot;12535&quot;,&quot;pages&quot;:&quot;71–87&quot;,&quot;publisher&quot;:&quot;Springer&quot;,&quot;year&quot;:&quot;2020&quot;,&quot;doi&quot;:&quot;10.1007/978-3-030-66415-2_5&quot;,&quot;abbr&quot;:&quot;ECCV&quot;,&quot;abstract&quot;:&quot;Deep neural networks have been successful in diverse\n                  discriminative classification tasks, although, they\n                  are poorly calibrated often assigning high\n                  probability to misclassified predictions. Potential\n                  consequences could lead to trustworthiness and\n                  accountability of the models when deployed in real\n                  applications, where predictions are evaluated based\n                  on their confidence scores. Existing solutions\n                  suggest the benefits attained by combining deep\n                  neural networks and Bayesian inference to quantify\n                  uncertainty over the models’ predictions for\n                  ambiguous datapoints. In this work we propose to\n                  validate and test the efficacy of likelihood based\n                  models in the task of out of distribution detection\n                  (OoD). Across different datasets and metrics we show\n                  that Bayesian deep learning models on certain\n                  occasions marginally outperform conventional neural\n                  networks and in the event of minimal overlap between\n                  in/out distribution classes, even the best models\n                  exhibit a reduction in AUC scores in detecting OoD\n                  data. Preliminary investigations indicate the\n                  potential inherent role of bias due to choices of\n                  initialisation, architecture or activation\n                  functions. We hypothesise that the sensitivity of\n                  neural networks to unseen inputs could be a\n                  multi-factor phenomenon arising from the different\n                  architectural design choices often amplified by the\n                  curse of dimensionality. Furthermore, we perform a\n                  study to find the effect of the adversarial noise\n                  resistance methods on in and out-of-distribution\n                  performance, as well as, also investigate\n                  adversarial noise robustness of Bayesian deep\n                  learners.&quot;,&quot;arxiv&quot;:&quot;2009.01798&quot;} -->
          <div class="periodical">
            <em>In Proceedings of Computer Vision - (ECCV) Workshops,</em> 2020
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/2009.01798" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep neural networks have been successful in diverse
                  discriminative classification tasks, although, they
                  are poorly calibrated often assigning high
                  probability to misclassified predictions. Potential
                  consequences could lead to trustworthiness and
                  accountability of the models when deployed in real
                  applications, where predictions are evaluated based
                  on their confidence scores. Existing solutions
                  suggest the benefits attained by combining deep
                  neural networks and Bayesian inference to quantify
                  uncertainty over the models’ predictions for
                  ambiguous datapoints. In this work we propose to
                  validate and test the efficacy of likelihood based
                  models in the task of out of distribution detection
                  (OoD). Across different datasets and metrics we show
                  that Bayesian deep learning models on certain
                  occasions marginally outperform conventional neural
                  networks and in the event of minimal overlap between
                  in/out distribution classes, even the best models
                  exhibit a reduction in AUC scores in detecting OoD
                  data. Preliminary investigations indicate the
                  potential inherent role of bias due to choices of
                  initialisation, architecture or activation
                  functions. We hypothesise that the sensitivity of
                  neural networks to unseen inputs could be a
                  multi-factor phenomenon arising from the different
                  architectural design choices often amplified by the
                  curse of dimensionality. Furthermore, we perform a
                  study to find the effect of the adversarial noise
                  resistance methods on in and out-of-distribution
                  performance, as well as, also investigate
                  adversarial noise robustness of Bayesian deep
                  learners.</p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICML</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2020a&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2020a,\n  author = {Mitros, John and Pakrashi, Arjun and Mac Namee, Brian},\n  title = {A Comparison of Bayesian Deep Learning for Out of\n                    Distribution Detection and Uncertainty Estimation},\n  booktitle = {Proceedings of the 37th International Conference of\n                    Machine Learning - (ICML) Workshops,},\n  volume = {119},\n  year = {2020},\n  abbr = {ICML}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Pakrashi, Arjun and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Arjun&quot;,&quot;last&quot;:&quot;Pakrashi&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Arjun&quot;,&quot;author_1_last&quot;:&quot;Pakrashi&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Brian&quot;,&quot;author_2_last&quot;:&quot;Mac Namee&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;A Comparison of Bayesian Deep Learning for Out of\n                  Distribution Detection and Uncertainty Estimation&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 37th International Conference of\n                  Machine Learning - (ICML) Workshops,&quot;,&quot;volume&quot;:&quot;119&quot;,&quot;year&quot;:&quot;2020&quot;,&quot;abbr&quot;:&quot;ICML&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2020a\&quot;&gt;Mitros, J., Pakrashi, A., &amp;amp; Mac Namee, B. (2020). A Comparison of Bayesian Deep Learning for Out of\n                  Distribution Detection and Uncertainty Estimation. &lt;i&gt;Proceedings of the 37th International Conference Of\n                  Machine Learning - (ICML) Workshops,&lt;/i&gt; &lt;i&gt;119&lt;/i&gt;.&lt;/span&gt;&quot; -->
        <div id="mitros2020a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Comparison of Bayesian Deep Learning for Out of
                  Distribution Detection and Uncertainty Estimation</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, <a href="https://scholar.google.com/citations?user=G0FkHtYAAAAJ" target="_blank" rel="noopener noreferrer">Pakrashi, Arjun</a>, and <a href="https://people.ucd.ie/brian.macnamee" target="_blank" rel="noopener noreferrer">Mac Namee, Brian</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2020a&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2020a,\n  author = {Mitros, John and Pakrashi, Arjun and Mac Namee, Brian},\n  title = {A Comparison of Bayesian Deep Learning for Out of\n                    Distribution Detection and Uncertainty Estimation},\n  booktitle = {Proceedings of the 37th International Conference of\n                    Machine Learning - (ICML) Workshops,},\n  volume = {119},\n  year = {2020},\n  abbr = {ICML}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Pakrashi, Arjun and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Arjun&quot;,&quot;last&quot;:&quot;Pakrashi&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Arjun&quot;,&quot;author_1_last&quot;:&quot;Pakrashi&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Brian&quot;,&quot;author_2_last&quot;:&quot;Mac Namee&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;A Comparison of Bayesian Deep Learning for Out of\n                  Distribution Detection and Uncertainty Estimation&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 37th International Conference of\n                  Machine Learning - (ICML) Workshops,&quot;,&quot;volume&quot;:&quot;119&quot;,&quot;year&quot;:&quot;2020&quot;,&quot;abbr&quot;:&quot;ICML&quot;} -->
          <div class="periodical">
            <em>In Proceedings of the 37th International Conference of
                  Machine Learning - (ICML) Workshops,</em> 2020
          </div>

          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AICS</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2019&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2019,\n  author = {Mitros, John and Mac Namee, Brian},\n  title = {On the Validity of Bayesian Neural Networks for\n                    Uncertainty Estimation},\n  booktitle = {Proceedings of the 27th Irish Conference on\n                    Artificial Intelligence and Cognitive Science -\n                    (AICS),},\n  series = {CEUR Workshop Proceedings},\n  volume = {2563},\n  pages = {140--151},\n  year = {2019},\n  arxiv = {1912.01530},\n  code = {https://arxiv.org/abs/1912.01530},\n  slides = {https://arxiv.org/abs/1912.01530},\n  pdf = {https://arxiv.org/abs/1912.01530},\n  talk = {adios-icml17-poster.pdf},\n  abbr = {AICS}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;Mac Namee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;On the Validity of Bayesian Neural Networks for\n                  Uncertainty Estimation&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 27th Irish Conference on\n                  Artificial Intelligence and Cognitive Science -\n                  (AICS),&quot;,&quot;series&quot;:&quot;CEUR Workshop Proceedings&quot;,&quot;volume&quot;:&quot;2563&quot;,&quot;pages&quot;:&quot;140–151&quot;,&quot;year&quot;:&quot;2019&quot;,&quot;arxiv&quot;:&quot;1912.01530&quot;,&quot;code&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;slides&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;pdf&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;talk&quot;:&quot;adios-icml17-poster.pdf&quot;,&quot;abbr&quot;:&quot;AICS&quot;,&quot;abstract&quot;:&quot;Deep neural networks (DNN) are versatile parametric\n                  models utilised successfully in a diverse number of\n                  tasks and domains. However, they have\n                  limitations—particularly from their lack of\n                  robustness and over-sensitivity to out of\n                  distribution samples. Bayesian Neural Networks, due\n                  to their formulation under the Bayesian framework,\n                  provide a principled approach to building neural\n                  networks that address these limitations. This paper\n                  describes a study that empirically evaluates and\n                  compares Bayesian Neural Networks to their\n                  equivalent point estimate Deep Neural Networks to\n                  quantify the predictive uncertainty induced by their\n                  parameters, as well as their performance in view of\n                  this uncertainty. In this study, we evaluated and\n                  compared three point estimate deep neural networks\n                  against comparable Bayesian neural network\n                  alternatives using two well-known benchmark image\n                  classification datasets (CIFAR-10 and SVHN). &quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2019\&quot;&gt;Mitros, J., &amp;amp; Mac Namee, B. (2019). On the Validity of Bayesian Neural Networks for\n                  Uncertainty Estimation. &lt;i&gt;Proceedings of the 27th Irish Conference On\n                  Artificial Intelligence and Cognitive Science -\n                  (AICS),&lt;/i&gt; &lt;i&gt;2563&lt;/i&gt;, 140–151.&lt;/span&gt;&quot; -->
        <div id="mitros2019" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On the Validity of Bayesian Neural Networks for
                  Uncertainty Estimation</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, and <a href="https://people.ucd.ie/brian.macnamee" target="_blank" rel="noopener noreferrer">Mac Namee, Brian</a>
                  
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2019&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2019,\n  author = {Mitros, John and Mac Namee, Brian},\n  title = {On the Validity of Bayesian Neural Networks for\n                    Uncertainty Estimation},\n  booktitle = {Proceedings of the 27th Irish Conference on\n                    Artificial Intelligence and Cognitive Science -\n                    (AICS),},\n  series = {CEUR Workshop Proceedings},\n  volume = {2563},\n  pages = {140--151},\n  year = {2019},\n  arxiv = {1912.01530},\n  code = {https://arxiv.org/abs/1912.01530},\n  slides = {https://arxiv.org/abs/1912.01530},\n  pdf = {https://arxiv.org/abs/1912.01530},\n  talk = {adios-icml17-poster.pdf},\n  abbr = {AICS}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John and Mac Namee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;Mac Namee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;Mac Namee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;On the Validity of Bayesian Neural Networks for\n                  Uncertainty Estimation&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 27th Irish Conference on\n                  Artificial Intelligence and Cognitive Science -\n                  (AICS),&quot;,&quot;series&quot;:&quot;CEUR Workshop Proceedings&quot;,&quot;volume&quot;:&quot;2563&quot;,&quot;pages&quot;:&quot;140–151&quot;,&quot;year&quot;:&quot;2019&quot;,&quot;arxiv&quot;:&quot;1912.01530&quot;,&quot;code&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;slides&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;pdf&quot;:&quot;https://arxiv.org/abs/1912.01530&quot;,&quot;talk&quot;:&quot;adios-icml17-poster.pdf&quot;,&quot;abbr&quot;:&quot;AICS&quot;,&quot;abstract&quot;:&quot;Deep neural networks (DNN) are versatile parametric\n                  models utilised successfully in a diverse number of\n                  tasks and domains. However, they have\n                  limitations—particularly from their lack of\n                  robustness and over-sensitivity to out of\n                  distribution samples. Bayesian Neural Networks, due\n                  to their formulation under the Bayesian framework,\n                  provide a principled approach to building neural\n                  networks that address these limitations. This paper\n                  describes a study that empirically evaluates and\n                  compares Bayesian Neural Networks to their\n                  equivalent point estimate Deep Neural Networks to\n                  quantify the predictive uncertainty induced by their\n                  parameters, as well as their performance in view of\n                  this uncertainty. In this study, we evaluated and\n                  compared three point estimate deep neural networks\n                  against comparable Bayesian neural network\n                  alternatives using two well-known benchmark image\n                  classification datasets (CIFAR-10 and SVHN). &quot;} -->
          <div class="periodical">
            <em>In Proceedings of the 27th Irish Conference on
                  Artificial Intelligence and Cognitive Science -
                  (AICS),</em> 2019
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1912.01530" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="https://arxiv.org/abs/1912.01530" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
            <a href="https://arxiv.org/abs/1912.01530" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
            <a href="https://arxiv.org/abs/1912.01530" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Slides</a>
            <a href="adios-icml17-poster.pdf" class="btn btn-sm z-depth-0" role="button">Talk</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Deep neural networks (DNN) are versatile parametric
                  models utilised successfully in a diverse number of
                  tasks and domains. However, they have
                  limitations—particularly from their lack of
                  robustness and over-sensitivity to out of
                  distribution samples. Bayesian Neural Networks, due
                  to their formulation under the Bayesian framework,
                  provide a principled approach to building neural
                  networks that address these limitations. This paper
                  describes a study that empirically evaluates and
                  compares Bayesian Neural Networks to their
                  equivalent point estimate Deep Neural Networks to
                  quantify the predictive uncertainty induced by their
                  parameters, as well as their performance in view of
                  this uncertainty. In this study, we evaluated and
                  compared three point estimate deep neural networks
                  against comparable Bayesian neural network
                  alternatives using two well-known benchmark image
                  classification datasets (CIFAR-10 and SVHN). </p>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2019b&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2019b,\n  title = {A Categorisation of Post-hoc Explanations for\n                    Predictive Models},\n  author = {Mitros, John and MacNamee, Brian},\n  booktitle = {Association for the Advancement of Artificial\n                    Intelligence - (AAAI) Spring Symposia on\n                    Story-Enabled Intelligence,},\n  year = {2019},\n  abbr = {AAAI},\n  html = {http://logical.ai/story/schedule.html},\n  arxiv = {904.02495}\n}\n&quot;,&quot;title&quot;:&quot;A Categorisation of Post-hoc Explanations for\n                  Predictive Models&quot;,&quot;author&quot;:&quot;Mitros, John and MacNamee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;MacNamee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;MacNamee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;booktitle&quot;:&quot;Association for the Advancement of Artificial\n                  Intelligence - (AAAI) Spring Symposia on\n                  Story-Enabled Intelligence,&quot;,&quot;year&quot;:&quot;2019&quot;,&quot;abstract&quot;:&quot;The ubiquity of machine learning based predictive\n                  models in modern society naturally leads people to\n                  ask how trustworthy those models are? In predictive\n                  modeling, it is quite common to induce a trade-off\n                  between accuracy and interpretability. For instance,\n                  doctors would like to know how effective some\n                  treatment will be for a patient or why the model\n                  suggested a particular medication for a patient\n                  exhibiting those symptoms? We acknowledge that the\n                  necessity for interpretability is a consequence of\n                  an incomplete formalisation of the problem, or more\n                  precisely of multiple meanings adhered to a\n                  particular concept. For certain problems, it is not\n                  enough to get the answer (what), the model also has\n                  to provide an explanation of how it came to that\n                  conclusion (why), because a correct prediction, only\n                  partially solves the original problem. In this\n                  article we extend existing categorisation of\n                  techniques to aid model interpretability and test\n                  this categorisation.&quot;,&quot;abbr&quot;:&quot;AAAI&quot;,&quot;html&quot;:&quot;http://logical.ai/story/schedule.html&quot;,&quot;arxiv&quot;:&quot;904.02495&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2019b\&quot;&gt;Mitros, J., &amp;amp; MacNamee, B. (2019). A Categorisation of Post-hoc Explanations for\n                  Predictive Models. &lt;i&gt;Association for the Advancement of Artificial\n                  Intelligence - (AAAI) Spring Symposia On\n                  Story-Enabled Intelligence,&lt;/i&gt;&lt;/span&gt;&quot; -->
        <div id="mitros2019b" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Categorisation of Post-hoc Explanations for
                  Predictive Models</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, and MacNamee, Brian
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2019b&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2019b,\n  title = {A Categorisation of Post-hoc Explanations for\n                    Predictive Models},\n  author = {Mitros, John and MacNamee, Brian},\n  booktitle = {Association for the Advancement of Artificial\n                    Intelligence - (AAAI) Spring Symposia on\n                    Story-Enabled Intelligence,},\n  year = {2019},\n  abbr = {AAAI},\n  html = {http://logical.ai/story/schedule.html},\n  arxiv = {904.02495}\n}\n&quot;,&quot;title&quot;:&quot;A Categorisation of Post-hoc Explanations for\n                  Predictive Models&quot;,&quot;author&quot;:&quot;Mitros, John and MacNamee, Brian&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Brian&quot;,&quot;last&quot;:&quot;MacNamee&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Brian&quot;,&quot;author_1_last&quot;:&quot;MacNamee&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;booktitle&quot;:&quot;Association for the Advancement of Artificial\n                  Intelligence - (AAAI) Spring Symposia on\n                  Story-Enabled Intelligence,&quot;,&quot;year&quot;:&quot;2019&quot;,&quot;abstract&quot;:&quot;The ubiquity of machine learning based predictive\n                  models in modern society naturally leads people to\n                  ask how trustworthy those models are? In predictive\n                  modeling, it is quite common to induce a trade-off\n                  between accuracy and interpretability. For instance,\n                  doctors would like to know how effective some\n                  treatment will be for a patient or why the model\n                  suggested a particular medication for a patient\n                  exhibiting those symptoms? We acknowledge that the\n                  necessity for interpretability is a consequence of\n                  an incomplete formalisation of the problem, or more\n                  precisely of multiple meanings adhered to a\n                  particular concept. For certain problems, it is not\n                  enough to get the answer (what), the model also has\n                  to provide an explanation of how it came to that\n                  conclusion (why), because a correct prediction, only\n                  partially solves the original problem. In this\n                  article we extend existing categorisation of\n                  techniques to aid model interpretability and test\n                  this categorisation.&quot;,&quot;abbr&quot;:&quot;AAAI&quot;,&quot;html&quot;:&quot;http://logical.ai/story/schedule.html&quot;,&quot;arxiv&quot;:&quot;904.02495&quot;} -->
          <div class="periodical">
            <em>In Association for the Advancement of Artificial
                  Intelligence - (AAAI) Spring Symposia on
                  Story-Enabled Intelligence,</em> 2019
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/904.02495" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
            <a href="http://logical.ai/story/schedule.html" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The ubiquity of machine learning based predictive
                  models in modern society naturally leads people to
                  ask how trustworthy those models are? In predictive
                  modeling, it is quite common to induce a trade-off
                  between accuracy and interpretability. For instance,
                  doctors would like to know how effective some
                  treatment will be for a patient or why the model
                  suggested a particular medication for a patient
                  exhibiting those symptoms? We acknowledge that the
                  necessity for interpretability is a consequence of
                  an incomplete formalisation of the problem, or more
                  precisely of multiple meanings adhered to a
                  particular concept. For certain problems, it is not
                  enough to get the answer (what), the model also has
                  to provide an explanation of how it came to that
                  conclusion (why), because a correct prediction, only
                  partially solves the original problem. In this
                  article we extend existing categorisation of
                  techniques to aid model interpretability and test
                  this categorisation.</p>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2018&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2018,\n  title = {Denoising Dictionary Learning Against Perturbations},\n  author = {Mitros, John and Bridge, Derek and Prestwich, Steven},\n  booktitle = {Proceedings of the 32nd Association for the\n                    Advancement of Artificial Intelligence - (AAAI)\n                    Workshops,},\n  year = {2018},\n  abbr = {AAAI},\n  arxiv = {1801.02257}\n}\n&quot;,&quot;title&quot;:&quot;Denoising Dictionary Learning Against Perturbations&quot;,&quot;author&quot;:&quot;Mitros, John and Bridge, Derek and Prestwich, Steven&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Derek&quot;,&quot;last&quot;:&quot;Bridge&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Steven&quot;,&quot;last&quot;:&quot;Prestwich&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Derek&quot;,&quot;author_1_last&quot;:&quot;Bridge&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Steven&quot;,&quot;author_2_last&quot;:&quot;Prestwich&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 32nd Association for the\n                  Advancement of Artificial Intelligence - (AAAI)\n                  Workshops,&quot;,&quot;year&quot;:&quot;2018&quot;,&quot;abstract&quot;:&quot;We propose denoising dictionary learning (DDL), a\n                  simple yet effective technique as a protection\n                  measure against adversarial perturbations. We\n                  examined denoising dictionary learning on MNIST and\n                  CIFAR10 perturbed under two different perturbation\n                  techniques, fast gradient sign (FGSM) and jacobian\n                  saliency maps (JSMA). We evaluated it against five\n                  different deep neural networks (DNN) representing\n                  the building blocks of most recent architectures\n                  indicating a successive progression of model\n                  complexity of each other. We show that each model\n                  tends to capture different representations based on\n                  their architecture. For each model we recorded its\n                  accuracy both on the perturbed test data previously\n                  misclassified with high confidence and on the\n                  denoised one after the reconstruction using\n                  dictionary learning. The reconstruction quality of\n                  each data point is assessed by means of PSNR (Peak\n                  Signal to Noise Ratio) and Structure Similarity\n                  Index (SSI).  We show that after applying (DDL) the\n                  reconstruction of the original data point from a\n                  noisy sample results in a correct prediction with\n                  high confidence.&quot;,&quot;abbr&quot;:&quot;AAAI&quot;,&quot;arxiv&quot;:&quot;1801.02257&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2018\&quot;&gt;Mitros, J., Bridge, D., &amp;amp; Prestwich, S. (2018). Denoising Dictionary Learning Against Perturbations. &lt;i&gt;Proceedings of the 32nd Association for The\n                  Advancement of Artificial Intelligence - (AAAI)\n                  Workshops,&lt;/i&gt;&lt;/span&gt;&quot; -->
        <div id="mitros2018" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Denoising Dictionary Learning Against Perturbations</div>
          <!-- Author -->
          <div class="author">
                  <em>Mitros, John</em>, Bridge, Derek, and Prestwich, Steven
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2018&quot;,&quot;type&quot;:&quot;inproceedings&quot;,&quot;bibtex&quot;:&quot;@inproceedings{mitros2018,\n  title = {Denoising Dictionary Learning Against Perturbations},\n  author = {Mitros, John and Bridge, Derek and Prestwich, Steven},\n  booktitle = {Proceedings of the 32nd Association for the\n                    Advancement of Artificial Intelligence - (AAAI)\n                    Workshops,},\n  year = {2018},\n  abbr = {AAAI},\n  arxiv = {1801.02257}\n}\n&quot;,&quot;title&quot;:&quot;Denoising Dictionary Learning Against Perturbations&quot;,&quot;author&quot;:&quot;Mitros, John and Bridge, Derek and Prestwich, Steven&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Derek&quot;,&quot;last&quot;:&quot;Bridge&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;},{&quot;first&quot;:&quot;Steven&quot;,&quot;last&quot;:&quot;Prestwich&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;author_1_first&quot;:&quot;Derek&quot;,&quot;author_1_last&quot;:&quot;Bridge&quot;,&quot;author_1_prefix&quot;:&quot;&quot;,&quot;author_1_suffix&quot;:&quot;&quot;,&quot;author_2_first&quot;:&quot;Steven&quot;,&quot;author_2_last&quot;:&quot;Prestwich&quot;,&quot;author_2_prefix&quot;:&quot;&quot;,&quot;author_2_suffix&quot;:&quot;&quot;,&quot;booktitle&quot;:&quot;Proceedings of the 32nd Association for the\n                  Advancement of Artificial Intelligence - (AAAI)\n                  Workshops,&quot;,&quot;year&quot;:&quot;2018&quot;,&quot;abstract&quot;:&quot;We propose denoising dictionary learning (DDL), a\n                  simple yet effective technique as a protection\n                  measure against adversarial perturbations. We\n                  examined denoising dictionary learning on MNIST and\n                  CIFAR10 perturbed under two different perturbation\n                  techniques, fast gradient sign (FGSM) and jacobian\n                  saliency maps (JSMA). We evaluated it against five\n                  different deep neural networks (DNN) representing\n                  the building blocks of most recent architectures\n                  indicating a successive progression of model\n                  complexity of each other. We show that each model\n                  tends to capture different representations based on\n                  their architecture. For each model we recorded its\n                  accuracy both on the perturbed test data previously\n                  misclassified with high confidence and on the\n                  denoised one after the reconstruction using\n                  dictionary learning. The reconstruction quality of\n                  each data point is assessed by means of PSNR (Peak\n                  Signal to Noise Ratio) and Structure Similarity\n                  Index (SSI).  We show that after applying (DDL) the\n                  reconstruction of the original data point from a\n                  noisy sample results in a correct prediction with\n                  high confidence.&quot;,&quot;abbr&quot;:&quot;AAAI&quot;,&quot;arxiv&quot;:&quot;1801.02257&quot;} -->
          <div class="periodical">
            <em>In Proceedings of the 32nd Association for the
                  Advancement of Artificial Intelligence - (AAAI)
                  Workshops,</em> 2018
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1801.02257" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>We propose denoising dictionary learning (DDL), a
                  simple yet effective technique as a protection
                  measure against adversarial perturbations. We
                  examined denoising dictionary learning on MNIST and
                  CIFAR10 perturbed under two different perturbation
                  techniques, fast gradient sign (FGSM) and jacobian
                  saliency maps (JSMA). We evaluated it against five
                  different deep neural networks (DNN) representing
                  the building blocks of most recent architectures
                  indicating a successive progression of model
                  complexity of each other. We show that each model
                  tends to capture different representations based on
                  their architecture. For each model we recorded its
                  accuracy both on the perturbed test data previously
                  misclassified with high confidence and on the
                  denoised one after the reconstruction using
                  dictionary learning. The reconstruction quality of
                  each data point is assessed by means of PSNR (Peak
                  Signal to Noise Ratio) and Structure Similarity
                  Index (SSI).  We show that after applying (DDL) the
                  reconstruction of the original data point from a
                  noisy sample results in a correct prediction with
                  high confidence.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

<p><br>
<br></p>
<h2 id="preprints">preprints</h2>

<!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2016</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">arXiv</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2016&quot;,&quot;type&quot;:&quot;report&quot;,&quot;bibtex&quot;:&quot;@manual{mitros2016,\n  author = {Mitros, John},\n  title = {Content-based image retrieval tutorial},\n  type = {report},\n  year = {2016},\n  abbr = {arXiv},\n  arxiv = {1608.03811}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Content-based image retrieval tutorial&quot;,&quot;year&quot;:&quot;2016&quot;,&quot;abstract&quot;:&quot;This paper functions as a tutorial for individuals\n                  interested to enter the field of information\n                  retrieval but wouldn’t know where to begin from. It\n                  describes two fundamental yet efficient image\n                  retrieval techniques, the first being k - nearest\n                  neighbors (knn) and the second support vector\n                  machines(svm). The goal is to provide the reader\n                  with both the theoretical and practical aspects in\n                  order to acquire a better understanding. Along with\n                  this tutorial we have also developed the equivalent\n                  software1 using the MATLAB environment in order to\n                  illustrate the techniques, so that the reader can\n                  have a hands-on experience.&quot;,&quot;abbr&quot;:&quot;arXiv&quot;,&quot;arxiv&quot;:&quot;1608.03811&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2016\&quot;&gt;Mitros, J. (2016). &lt;i&gt;Content-based image retrieval tutorial&lt;/i&gt; [Report].&lt;/span&gt;&quot; -->
        <div id="mitros2016" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Content-based image retrieval tutorial</div>
          <!-- Author -->
          <div class="author">
                <em>Mitros, John</em>
          </div>

          <!-- Journal/Book title and date -->
          <!-- {&quot;key&quot;:&quot;mitros2016&quot;,&quot;type&quot;:&quot;report&quot;,&quot;bibtex&quot;:&quot;@manual{mitros2016,\n  author = {Mitros, John},\n  title = {Content-based image retrieval tutorial},\n  type = {report},\n  year = {2016},\n  abbr = {arXiv},\n  arxiv = {1608.03811}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Content-based image retrieval tutorial&quot;,&quot;year&quot;:&quot;2016&quot;,&quot;abstract&quot;:&quot;This paper functions as a tutorial for individuals\n                  interested to enter the field of information\n                  retrieval but wouldn’t know where to begin from. It\n                  describes two fundamental yet efficient image\n                  retrieval techniques, the first being k - nearest\n                  neighbors (knn) and the second support vector\n                  machines(svm). The goal is to provide the reader\n                  with both the theoretical and practical aspects in\n                  order to acquire a better understanding. Along with\n                  this tutorial we have also developed the equivalent\n                  software1 using the MATLAB environment in order to\n                  illustrate the techniques, so that the reader can\n                  have a hands-on experience.&quot;,&quot;abbr&quot;:&quot;arXiv&quot;,&quot;arxiv&quot;:&quot;1608.03811&quot;} -->
          <div class="periodical">
            2016
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a href="http://arxiv.org/abs/1608.03811" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">arXiv</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper functions as a tutorial for individuals
                  interested to enter the field of information
                  retrieval but wouldn’t know where to begin from. It
                  describes two fundamental yet efficient image
                  retrieval techniques, the first being k - nearest
                  neighbors (knn) and the second support vector
                  machines(svm). The goal is to provide the reader
                  with both the theoretical and practical aspects in
                  order to acquire a better understanding. Along with
                  this tutorial we have also developed the equivalent
                  software1 using the MATLAB environment in order to
                  illustrate the techniques, so that the reader can
                  have a hands-on experience.</p>
          </div>
        </div>
      </div>
</li></ol>


</div>

<p><br>
<br></p>
<h2 id="theses">theses</h2>

<!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2022</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PhD</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2022&quot;,&quot;type&quot;:&quot;thesis&quot;,&quot;bibtex&quot;:&quot;@thesis{mitros2022,\n  author = {Mitros, John},\n  title = {Bayesian Neural Networks for Out-of-Distribution Detection},\n  school = {University College Dublin},\n  year = {2022},\n  abbr = {PhD},\n  pdf = {PhD.pdf}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Bayesian Neural Networks for Out-of-Distribution Detection&quot;,&quot;school&quot;:&quot;University College Dublin&quot;,&quot;year&quot;:&quot;2022&quot;,&quot;abbr&quot;:&quot;PhD&quot;,&quot;pdf&quot;:&quot;PhD.pdf&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2022\&quot;&gt;Mitros, J. (2022). &lt;i&gt;Bayesian Neural Networks for Out-of-Distribution Detection&lt;/i&gt;. University College Dublin.&lt;/span&gt;&quot; -->
        <div id="mitros2022" class="col-sm-8">
        <span id="mitros2022">Mitros, J. (2022). <i>Bayesian Neural Networks for Out-of-Distribution Detection</i>. University College Dublin.</span>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="/assets/pdf/PhD.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          
        </div>
      </div>
</li></ol>

  <h2 class="year">2014</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">MSc</abbr></div>

        <!-- Entry bib key -->
        <!-- {&quot;key&quot;:&quot;mitros2014&quot;,&quot;type&quot;:&quot;thesis&quot;,&quot;bibtex&quot;:&quot;@thesis{mitros2014,\n  author = {Mitros, John},\n  title = {Discovering Latent Factors in Lyrics of Greek Folk\n                    Songs. [In Greek]},\n  school = {Aristotle University},\n  year = {2014},\n  note = {In Greek},\n  abbr = {MSc},\n  pdf = {msc-thesis.pdf}\n}\n&quot;,&quot;author&quot;:&quot;Mitros, John&quot;,&quot;author_array&quot;:[{&quot;first&quot;:&quot;John&quot;,&quot;last&quot;:&quot;Mitros&quot;,&quot;prefix&quot;:&quot;&quot;,&quot;suffix&quot;:&quot;&quot;}],&quot;author_0_first&quot;:&quot;John&quot;,&quot;author_0_last&quot;:&quot;Mitros&quot;,&quot;author_0_prefix&quot;:&quot;&quot;,&quot;author_0_suffix&quot;:&quot;&quot;,&quot;title&quot;:&quot;Discovering Latent Factors in Lyrics of Greek Folk\n                  Songs. [In Greek]&quot;,&quot;school&quot;:&quot;Aristotle University&quot;,&quot;year&quot;:&quot;2014&quot;,&quot;note&quot;:&quot;In Greek&quot;,&quot;abbr&quot;:&quot;MSc&quot;,&quot;pdf&quot;:&quot;msc-thesis.pdf&quot;} <br /> -->
        <!-- &quot;&lt;span id=\&quot;mitros2014\&quot;&gt;Mitros, J. (2014). &lt;i&gt;Discovering Latent Factors in Lyrics of Greek Folk\n                  Songs. [In Greek]&lt;/i&gt;. Aristotle University.&lt;/span&gt;&quot; -->
        <div id="mitros2014" class="col-sm-8">
        <span id="mitros2014">Mitros, J. (2014). <i>Discovering Latent Factors in Lyrics of Greek Folk
                  Songs. [In Greek]</i>. Aristotle University.</span>

          <!-- Links/Buttons -->
          <div class="links">
            <a href="/assets/pdf/msc-thesis.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          
        </div>
      </div>
</li></ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 John  Mitros. With 💜 <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

